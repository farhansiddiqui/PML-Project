---
title: "Activity prediction from accelerometer data"
author: "Farhan Siddiqui"
date: "Friday, October 24, 2014"
output: html_document
---

This paper explores the use of acceleromoter data from the belt, forearm, arm, and dumbell of 6 participants in order to predict barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


```{r}
#read data
set.seed(1234)
setwd("~/R/PracticalML/Project")
activity <- read.csv(file="pml-training.csv",head=TRUE,sep=",", na.strings=c("NA", "#DIV/0!"))
```

We first explore the training dataset provided

```{r results='hide'}
str(activity)

```
Structure command reveals that a large number of columns have lots of NAs. We now visualize the number of NAs graphically.
```{r}
hist(colSums(is.na(activity)), main="# of NAs vs. # Freq of Columns")
```
<br>
As can be seen from the histogram, about 100 columns have mostly NAs in the data set. To reduce the dimensionality of the data, we will now exclude any columns which have more than 95% NAs in the data as the information content of such columns is extremely low and they would not add much to prediction accuracy.

```{r}
activity <- activity[,colSums(is.na(activity))< 0.95*nrow(activity)]
```
We are still left with 59 predictors and 1 response varibale in the dataset. We will now use PCA to further reduce the number of predictors. We exclude first 7 predictors as they are indexes, names and dates that should not have any precitive value.

```{r results='hide'}
library(caret)
inTrain <- createDataPartition(y=activity$classe, p=0.7, list=FALSE)
training <- activity[inTrain,]
testing <- activity[-inTrain,]
pr <-prcomp(training[,-c(1:7,60)], center=T, scale=T)
```
```{r}
print(paste("Number of Principal Components : ",length(pr$sdev)))
plot(pr$x,col=training$classe,xlab='PC1',ylab='PC2',main="PC1 vs. PC2; Color = Activity Class")
```
Next we will use cross validation to explore how prediction error rate varies with # of predictors.

```{r results='hide'}
trainPC=predict(pr,training[,-c(1:7,60)])
library(randomForest)
```
```{r}
cv <- rfcv(trainPC, training$classe)
cv$error
plot(cv$n.var,cv$error,type="b",xlab="# of predictors",ylab="cv error", main="# of predictors vs. cv error")
```
<br>
Since error rate continues to drop as we include more predictors and as we want our model to be as accurate as possible, we will use all of the principal components to train our model.
```{r}
modelFit <- randomForest(training$classe~ .,data=trainPC)
modelFit
```
This gives us an OOB estimate of  error rate: `modelFit$err.rate` %
```{r}
testPC=predict(pr,testing[,-c(1:7,60)])
confusionMatrix(testing$classe,predict(modelFit,testPC))
```
As can be seen from the confusion matrix, we were able to precit over 98% of our test data set activity label correctly. Now that we have confidence in our model, we will use it to predict 20 test cases.
```{r}
testing <- read.csv(file="pml-testing.csv",head=TRUE,sep=",", na.strings=c("NA", "#DIV/0!"))
testPC=predict(pr,testing[,-c(1:7)])
answers = predict(modelFit,testPC)
answers
```
Finally we will write each answer as a sperate text file in order to submit the solution.
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```